---
title: "Hw3"
author: "Lianghui Li"
date: "9/18/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(knitr)
library(ggplot2)
```

## 3.3

### a

We know under gamma prior $G(a,b)$ and $y_i \mid \theta$ follows poisson, the posterior will be $G(a + y,b + n)$, where $y$ is number of the observed, $n$ is number of events.

The posterior distribution for A is $\theta_A \mid y_A$ ~ $gamma(120 + \sum^{10} y_{A_i} = 237, 10 + 10 = 20)$, The posterior distribution for B is $\theta_B \mid y_B$ ~ $gamma(12 + \sum^{10} y_{B_i} = 125, 1 + 13 = 14)$.


```{r}
y_a = c(12,9,12,14,13,13,15,8,15,6)
y_b = c(11,11,10,9,9,8,7,10,6,8,8,9,7)

a_a  = 120
b_a = 10

a_b = 12
b_b = 1
 
a_a_post = a_a + sum(y_a)
b_a_post =  b_a + length(y_a)

a_b_post = a_b + sum(y_b)
b_b_post = b_b + length(y_b)

a_mean_post = a_a_post / b_a_post
b_mean_post = a_b_post / b_b_post

a_var_post = a_a_post / b_a_post^2
b_var_post = a_b_post / b_b_post^2

ci_a_post = qgamma(c(0.025,0.975), a_a_post, b_a_post)
ci_b_post = qgamma(c(0.025,0.975), a_b_post, b_b_post)

df1 = data.frame(t(c(a_mean_post, a_var_post, ci_a_post)))
df1 = rbind(df1, c(b_mean_post, b_var_post, ci_b_post))
colnames(df1) = c("mean", "variance", "2.5%", "97.5%")
rownames(df1) = c("a", "b")

kable(df1)

```


###b

```{r}
n0 = seq(50)
a0 = 12 *n0
b0 = n0 

a_b_post = a0 + sum(y_b)
b_b_post = b0 + length(y_b)

mean_b_post = a_b_post /b_b_post

df2 = data.frame(n0, mean_b_post)

ggplot(df2, aes(x = n0, y = mean_b_post )) + geom_line()


```

From part a), we know that posterior expectation of $\theta_A$ is 11.85, in order to know what value $n_0$ is necessary for $\theta_B$ to achieve the same value, we can solve the equation $11.85 = \frac{12n_0 + 113}{n_0 +13}$, and $n_0$ should be at least 274.

###c

Given from the problem, we know that Type B mice are related to type A mice, which means they are not indepedent. with the equation $p(\theta_A, \theta_b) = p(\theta_A)p(\theta_B)$, that implies A and B are independent in terms of our prior belief; therefore, it does not make sense to have to equation above.


##4.1

Since prior for $\theta_2$ is $Beta(1,1)$ and the sampling is $Bino(50,30)$, so the posterior for $\theta_2$ is $Beta(31,21)$.

```{r}
theta = seq(0,1, by = 0.1)

y1 = 57
n1 = 100
y2 = 30
n2 = 50

p_y_theta <- dbeta(theta, y2 + 1, 1 + n2 - y2)
ptheta <- rep(1/length(theta), length(theta))
p_joint <- p_y_theta*ptheta
p_post <- p_joint/sum(p_joint)

theta2_mc <- sample(x = theta, 
                           size = 5000, 
                           replace = TRUE, 
                           prob = p_post)


p_y_theta1 = dbeta(theta, 1 + y1, 1+ n1 -y1)

p_joint1 <- p_y_theta1*ptheta
p_post1 <- p_joint1/sum(p_joint1)

theta1_mc <- sample(x = theta, 
                           size = 5000, 
                           replace = TRUE, 
                           prob = p_post1)

mean(theta1_mc < theta2_mc)

```

Therefore, $E(Pr(\theta_1 < \theta_2 \mid the data and prior)) = 0.3734$

