---
title: "hw4"
author: "Lianghui Li"
date: "9/23/2017"
output:
  pdf_document: default
  html_document: default
---

```{r}
library(ggplot2)
library(reshape2)
```



##4.3

###a

```{r}
y.a <- c(12,9,12,14,13,13,15,8,15,6) 
y.b <- c(11,11,10,9,9,8,7,10,6,8,8,9,7)

a.a <- 120
b.a <- 10

a.b <- 12
b.b <- 1

a.post.a =  a.a + sum(y.a) 
b.post.a = b.a + length(y.a)


set.seed(1)
s = 50000

pred.a =  matrix(nrow = s, ncol = length(y.a))

theta.samps <- rgamma(s, a.post.a, b.post.a)

for (i in seq_len(ncol(pred.a))) {
pred.a[, i] <- rpois(s, theta.samps)
}

a.result = apply(pred.a, 1, function(x) mean(x)/sd(x))

qplot(a.result, y=..density.., geom="histogram", binwidth = 0.5, breaks = seq(2,12, by = 1)) + geom_vline(xintercept = mean(y.a)/sd(y.a), color = 'red')

```


We can see from the graph that the observed value lies within high density region in the sample of posterior predictive distrbution. so the we expect the poisson model is able to represent the feature of the population of t.


###b

```{r}
a.post.b =  a.b + sum(y.b) 
b.post.b = b.b + length(y.b)


set.seed(1)
s = 50000

pred.b =  matrix(nrow = s, ncol = length(y.b))

theta.samps <- rgamma(s, a.post.b, b.post.b)

for (i in seq_len(ncol(pred.b))) {
pred.b[, i] <- rpois(s, theta.samps)
}

b.result = apply(pred.b, 1, function(x) mean(x)/sd(x))

qplot(b.result, y=..density.., geom="histogram", binwidth = 0.5, breaks = seq(2,8, by = 1)) + geom_vline(xintercept = mean(y.b)/sd(y.b), color = 'red')
```


However in this case, the observed value lies in the tail of the posterior predictive distrbution. This conflict might be casued by the inability of possion model in explaining the distritbuion of t or the small sample size in each simulation(13) causing the sampling variability.




##4.8


###a


```{r}
bach = scan("menchild30bach.dat")
nobach = scan("menchild30nobach.dat")
```




```{r}
a = 2
b = 1

a.post.a = a + sum(bach)
b.post.a = a + length(bach)

a.post.b = a + sum(nobach)
b.post.b = a + length(nobach)

set.seed(1)
s = 5000

ta.mc = rgamma(s, a.post.a, b.post.a)
tb.mc = rgamma(s, a.post.b, b.post.b)

a.mc = rpois(s, ta.mc)
b.mc = rpois(s, tb.mc)


r = range(c(a.mc, b.mc))
yseq = r[1] : r[2]

ya = rep(NA, length(seq))
yb = rep(NA, length(seq))

for(i in seq_along(yseq)) {
  ya[i] = sum(a.mc == yseq[i])
  yb[i] = sum(b.mc == yseq[i])

}

ya = ya/sum(ya)
yb = yb/sum(yb)

df1 = data.frame(cbind(ya,yb, factor(yseq)))
df2 = melt(df1, id.vars="V3")

ggplot(df2, aes(V3, value, fill=variable)) + 
  geom_bar(stat="identity", position="dodge")
```


###b


```{r}
quantile(b.mc - a.mc, probs=c(0.025, 0.975))
quantile(tb.mc - ta.mc, probs=c(0.025, 0.975))

```

We can see that the confidence interval for $\theta_B - \theta_A$ = (0.16, 0.74); which means for the population, there is 95% confidence that men who don't bachlor degree at the age 30's on average have more children than who have the degree. However, for a predictive individual, the one without degree might have two less or 4 more children than he has the degree on 95 out of 100 occasions.


###c


```{r}

set.seed(1)
y.sample <- as.numeric((table(nobach))/sum(table(nobach)))
r <- 0:6
yhat <- rpois(s, 1.4)
y.true <- rep(NA, length(r))
for(i in 1:7) { y.true[i] <- sum(yhat == r[i]) }
y.true <- y.true/sum(y.true)



df3 = data.frame(cbind(y.sample,y.true, factor(r)))
df4 = melt(df3, id.vars="V3")


ggplot(df4, aes(V3, value, fill=variable)) + 
  geom_bar(stat="identity", position="dodge")

```


In this case, the histogram in green is the possion distribution with $\theta = 1.4$, and the red are our empirical distrbution. Since the mode for empirical is close to 0, while the mode for possion is close to 2, the empirical distrbution has higher density in lower end than possion's, thus, possion model is not a good fit.

###d

```{r}
set.seed(1)
t0.mc = rep(NA, s)
t1.mc = rep(NA, s)
for(t in seq_len(s)) {
  dB.mc <- rpois(nobach, tb.mc[t])
  t0.mc[t] <- sum(dB.mc==0)
  t1.mc[t] <- sum(dB.mc==1)
}

df5 = data.frame(t0.mc, t1.mc)
ggplot(df5, aes(x= t0.mc, y= t1.mc)) + 
  geom_point() + 
  geom_jitter() +
  geom_vline(xintercept = sum(nobach==0), col=2, lty=2) +
  geom_hline(yintercept = sum(nobach==1), col=2, lty=2) +
  xlab('zero child') + ylab('one child')
```

As we can see from the graph, the predictive mean under possion model for both zero child and one child lie outside the clouds, which suggests possion model is not a good fit in this case.
